{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5691,"status":"ok","timestamp":1724440772804,"user":{"displayName":"Manish Bairwa","userId":"04014605488979557537"},"user_tz":-330},"id":"Mvl8utPYPBZP"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch import nn\n","import pandas as pd\n","import matplotlib.pyplot as plt # for making figures\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","from pprint import pprint"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":577,"status":"ok","timestamp":1724440777050,"user":{"displayName":"Manish Bairwa","userId":"04014605488979557537"},"user_tz":-330},"id":"15HwQoQyQC2I"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6MM3xblJVmRf"},"outputs":[],"source":["!pip install --upgrade nltk"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3263,"status":"ok","timestamp":1724440784028,"user":{"displayName":"Manish Bairwa","userId":"04014605488979557537"},"user_tz":-330},"id":"Ca4D6mUUQOyZ","outputId":"4d24e611-4231-420d-d444-454d1cbd21cf"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# !pip install --upgrade nltk\n","import nltk\n","from nltk.tokenize import sent_tokenize, RegexpTokenizer\n","from typing import Iterator\n","# Download NLTK data\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57061,"status":"ok","timestamp":1724440864963,"user":{"displayName":"Manish Bairwa","userId":"04014605488979557537"},"user_tz":-330},"id":"1DGt3Ic7PGXl","outputId":"27da060c-ccf6-43d0-cc69-4c931df976b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3170,"status":"ok","timestamp":1724440875586,"user":{"displayName":"Manish Bairwa","userId":"04014605488979557537"},"user_tz":-330},"id":"DuCKcKtxWG8l"},"outputs":[],"source":["\n","\n","filepath=\"/content/drive/MyDrive/model/paul_graham_essay.txt\"\n","\n","        # Split the content by two or more newline\n","\n","# Defining the function to replace tricky characters\n","def replace_characters(text: str) -> str:\n","    replacement_rules = {'“': '\"', '”': '\"', '’': \"'\", '--': ','}\n","    for symbol, replacement in replacement_rules.items():\n","        text = text.replace(symbol, replacement)\n","    return text\n","\n","# Defining the function to tokenize and preprocess sentences\n","def generate_tokenized_sentences(paragraph: str):\n","    word_tokenizer = RegexpTokenizer(r'[-\\'\\w]+')\n","    words=[]\n","    for sentence in sent_tokenize(paragraph):\n","        # Replace tricky characters\n","        sentence = replace_characters(sentence)\n","        sentence = sentence.lower()\n","        tokenized_sentence = word_tokenizer.tokenize(sentence)\n","\n","        # Lowercase the sentence\n","\n","        words.extend(tokenized_sentence)\n","\n","    return words\n","        # Append [END] and [START] to the tokenized sentenc\n","# Initializing an empty list to store tokenized sentences\n","words = []\n","with open(filepath, 'r') as file:\n","        content = file.read()\n","        words=generate_tokenized_sentences(content)\n","\n","# Processing each comment in the DataFrame\n","# Creating a text file to store the tokenized sentences\n","with open('/content/drive/MyDrive/model/processed_data.txt', 'w', encoding='utf-8') as file:\n","        file.write(\",\".join(words))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27Q9hpklOkNT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1669,"status":"ok","timestamp":1724440879440,"user":{"displayName":"Manish Bairwa","userId":"04014605488979557537"},"user_tz":-330},"id":"kVTRfwCIZ_Hf","outputId":"0c93f537-c209-4a7b-a9b9-d7f87bbc1a4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n"]}],"source":["\n","stoi={}\n","itos={}\n","words=[]\n","with open('/content/drive/MyDrive/model/processed_data.txt', 'r') as file:\n","        content = file.read()\n","        words=content.split(\",\")\n","        chars = []\n","        for word in words:\n","          for char in word:\n","            if char.isalpha() and char not in chars:\n","              chars.append(char)\n","        # Correctly build stoi and itos\n","        chars = sorted(set(char for word in words for char in word if char.isalpha()))\n","        stoi = {s: i for i, s in enumerate(chars)}\n","        itos = {i: s for s, i in stoi.items()}\n","\n","        # Ensure vocab_size is correct\n","        vocab_size = len(stoi)\n","\n","        if 'é' in stoi:\n","           del stoi['é']\n","\n","\n","        itos = {i:s for s,i in stoi.items()}\n","\n","\n","\n","print(stoi)\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":651,"status":"ok","timestamp":1724440884151,"user":{"displayName":"Manish Bairwa","userId":"04014605488979557537"},"user_tz":-330},"id":"iO1ScmdqcVT1"},"outputs":[],"source":["class NextChar(nn.Module):\n","  def __init__(self, block_size, vocab_size, emb_dim, hidden_size):\n","    super().__init__()\n","    self.emb = nn.Embedding(vocab_size, emb_dim)\n","    self.lin1 = nn.Linear(block_size * emb_dim, hidden_size)\n","    self.lin2 = nn.Linear(hidden_size, vocab_size)\n","  def forward(self, x):\n","    x = self.emb(x)\n","    x = x.view(x.shape[0], -1)\n","    x = torch.sin(self.lin1(x))\n","    x = self.lin2(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KC4gr9Ah9cFb"},"outputs":[],"source":["len(words)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGlWnGicbSrA"},"outputs":[],"source":["# import time\n","# def train_model(context_len,embed_size,vocab_size):\n","#   block_size = context_len # context length: how many characters do we take to predict the next one?\n","#   X, Y = [], []\n","#   for w in words[:]:\n","\n","#   #print(w)\n","#     context = [0] * block_size\n","#     # for ch in w + '.':\n","#     for ch in w:\n","#       if ch not in stoi:\n","#         continue\n","\n","#       ix = stoi[ch]\n","#       X.append(context)\n","#       Y.append(ix)\n","#       #print(''.join(itos[i] for i in context), '--->', itos[ix])\n","#       context = context[1:] + [ix] # crop and append\n","\n","#   X = torch.tensor(X).to(device)\n","#   Y = torch.tensor(Y).to(device)\n","#   # Train the model\n","#   model = NextChar(block_size, len(stoi), embed_size, 10).to(device)\n","#   model = torch.compile(model)\n","\n","#   loss_fn = nn.CrossEntropyLoss()\n","#   opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n","#   # Mini-batch training\n","#   batch_size = 4096\n","#   print_every = 100\n","#   elapsed_time = []\n","#   for epoch in range(1000):\n","#       start_time = time.time()\n","#       for i in range(0, X.shape[0], batch_size):\n","#           x = X[i:i+batch_size]\n","#           y = Y[i:i+batch_size]\n","#           y_pred = model(x)\n","#           loss = loss_fn(y_pred, y)\n","#           loss.backward()\n","#           opt.step()\n","#           opt.zero_grad()\n","#       end_time = time.time()\n","#       elapsed_time.append(end_time - start_time)\n","#       if epoch % print_every == 0:\n","#           print(epoch, loss.item())\n","\n","#   return model\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":862,"status":"ok","timestamp":1724440890230,"user":{"displayName":"Manish Bairwa","userId":"04014605488979557537"},"user_tz":-330},"id":"wWDEr8R0hL9h"},"outputs":[],"source":["def train_model(context_len, embed_size, vocab_size):\n","    block_size = context_len\n","    X, Y = [], []\n","\n","    for w in words:\n","        context = [0] * block_size\n","        for ch in w:\n","            if ch not in stoi:\n","                continue\n","\n","            ix = stoi[ch]\n","            if ix >= vocab_size:\n","                raise ValueError(f\"Index {ix} out of bounds for vocab_size {vocab_size}\")\n","\n","            X.append(context)\n","            Y.append(ix)\n","            context = context[1:] + [ix]\n","\n","    X = torch.tensor(X).to(device)\n","    Y = torch.tensor(Y).to(device)\n","\n","    model = NextChar(block_size, vocab_size, embed_size, 10).to(device)\n","    model = torch.compile(model)\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","    opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n","\n","    batch_size = 4096\n","    print_every = 100\n","    elapsed_time = []\n","\n","    for epoch in range(1000):\n","        start_time = time.time()\n","        for i in range(0, X.shape[0], batch_size):\n","            x = X[i:i+batch_size]\n","            y = Y[i:i+batch_size]\n","            y_pred = model(x)\n","            loss = loss_fn(y_pred, y)\n","            loss.backward()\n","            opt.step()\n","            opt.zero_grad()\n","        end_time = time.time()\n","        elapsed_time.append(end_time - start_time)\n","        if epoch % print_every == 0:\n","            print(epoch, loss.item())\n","\n","    return model\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":880,"status":"ok","timestamp":1724440930355,"user":{"displayName":"Manish Bairwa","userId":"04014605488979557537"},"user_tz":-330},"id":"-3gcVnsin_gw","outputId":"1f1d9703-499b-4a21-bff9-bebdc657ca17"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique characters: 26\n"]}],"source":["def debug_stoi():\n","    print(f\"Number of unique characters: {len(stoi)}\")\n","    for ch, idx in stoi.items():\n","        if idx >= len(stoi):\n","            print(f\"Character {ch} has an invalid index {idx}\")\n","\n","debug_stoi()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xMfzMhGp9cFd"},"outputs":[],"source":["# embedding_size=[2,5,10]\n","# context_length=[3,6,9]\n","# ectuple=[ (e,c)  for e in embedding_size for c in context_length]\n","# i=0\n","# for t in ectuple:\n","#     model=train_model(t[1],t[0],len(stoi)-1)\n","#     torch.save(model.state_dict(),f\"./model_{i}.pt\")\n","#     i+=1\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10262,"status":"ok","timestamp":1724446062200,"user":{"displayName":"Manish Bairwa","userId":"04014605488979557537"},"user_tz":-330},"id":"Pugu60mBgiD6","outputId":"7549c364-d088-490f-cd2e-ab3257f33333"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model 1/9 with embed_size=2 and context_len=3\n","An error occurred with model 0: name 'train_model' is not defined\n","Training model 2/9 with embed_size=2 and context_len=6\n","An error occurred with model 1: name 'train_model' is not defined\n","Training model 3/9 with embed_size=2 and context_len=9\n","An error occurred with model 2: name 'train_model' is not defined\n","Training model 4/9 with embed_size=5 and context_len=3\n","An error occurred with model 3: name 'train_model' is not defined\n","Training model 5/9 with embed_size=5 and context_len=6\n","An error occurred with model 4: name 'train_model' is not defined\n","Training model 6/9 with embed_size=5 and context_len=9\n","An error occurred with model 5: name 'train_model' is not defined\n","Training model 7/9 with embed_size=10 and context_len=3\n","An error occurred with model 6: name 'train_model' is not defined\n","Training model 8/9 with embed_size=10 and context_len=6\n","An error occurred with model 7: name 'train_model' is not defined\n","Training model 9/9 with embed_size=10 and context_len=9\n","An error occurred with model 8: name 'train_model' is not defined\n"]}],"source":["import time\n","import torch\n","import torch.nn as nn\n","\n","# Ensure this is the GPU device or CPU device depending on availability\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","embedding_size = [2, 5, 10]\n","context_length = [3, 6, 9]\n","ectuple = [(e, c) for e in embedding_size for c in context_length]\n","\n","for i, (embed_size, context_len) in enumerate(ectuple):\n","    try:\n","        print(f\"Training model {i+1}/{len(ectuple)} with embed_size={embed_size} and context_len={context_len}\")\n","\n","        model = train_model(context_len, embed_size, len(stoi))\n","\n","        # Ensure that the model was returned correctly and has state_dict\n","        if model is None:\n","            raise ValueError(\"Model is None. Training failed.\")\n","\n","        # Save model\n","        torch.save(model.state_dict(), f\"./model_{i}.pt\")\n","        print(f\"Model {i} saved successfully.\")\n","\n","    except Exception as e:\n","        print(f\"An error occurred with model {i}: {e}\")\n","        # Optionally add debugging details here\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i550MaX29cFe"},"outputs":[],"source":["model=train_model(9,10,len(stoi))\n","torch.save(model.state_dict(),\"./model_8.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cD2M2PWWc7gO"},"outputs":[],"source":["model=train_model(5,2,len(stoi))\n","torch.save(model.state_dict(),\"./model.pt\")\n","model1=NextChar(5,len(stoi),2,10)\n","model1.load_state_dict(torch.load(\"./model.pt\"),strict=False)\n","model1.eval()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24vOSIPqcUmZ"},"outputs":[],"source":["from sklearn.manifold import TSNE\n","\n","\n","\n","\n","def plot_emb(emb, itos,title):\n","    # Get the weights of the embedding layer\n","    weights = emb.weight.detach().cpu().numpy()\n","\n","    # Use PCA to reduce the dimensionality to 2\n","    tsne = TSNE(n_components=2, random_state=42)\n","    X_tsne = tsne.fit_transform(weights)\n","\n","    fig, ax = plt.subplots()\n","    ax.set_title(title)\n","    for i in range(len(itos)):\n","        x, y = X_tsne[i]\n","        ax.scatter(x, y, color='k')\n","        ax.text(x + 0.05, y + 0.05, itos[i])\n","\n","    return ax\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KUMKfg5V9cFh"},"outputs":[],"source":["emb={\"2\":0,\"5\":1,\"10\":2}\n","context={\"3\":0,\"6\":1,\"9\":2}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ThWNIDKO9cFh"},"outputs":[],"source":["for t in ectuple:\n","    model_number=emb[str(t[0])]*3+context[str(t[1])]\n","    model1 = NextChar(t[1],len(stoi),t[0], 10)\n","    model1.load_state_dict(torch.load(f\"./model_{model_number}.pt\",map_location=torch.device('cpu')), strict=False)\n","    plot_emb(model1.emb,itos,f\"Embedding Size {t[0]} and Context length {t[1]}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzfOD78zXoBC"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
